# 参考

[Full Preprocessing Tutorial | Kaggle](https://www.kaggle.com/akh64bit/full-preprocessing-tutorial)   2017年Kaggle肺部癌症冠军100万美元

[PS3.6 (nema.org)](http://dicom.nema.org/medical/dicom/current/output/pdf/part06.pdf)

[处理医疗影像的Python利器：PyDicom - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/59413289)

[初始DICOM以及pydicom的基础操作 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/154181400)

[论文阅读！kaggle比赛第一名--肺癌自动诊断系统 - 云+社区 - 腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/1161012)

# 医学图像

## 一. DICOM简介

患者的医学图像以DICOM文件格式进行存储，其中包含了图像信息以及患者的**PHI**（protected health information，即姓名、性别、年龄等），以及产生图像的设备的相关信息。

DICOM文件的内容一般由一个DICOM文件头和一个DICOM数据集组成，结构图如下所示：

<img src="https://tuchuang-1306197151.cos.ap-shanghai.myqcloud.com/typora本地图床/v2-dee6ada3ba82f829298a6a1e52563489_720w.jpg" alt="img" style="zoom:50%;" />

* **文件头**存放一些数据集的相关介绍信息
* 数据集
  * **值表示、值长度、值域**存放数据
  * TAG号存索引数据标签，分为4类： - **Patient** - **Study** - **Series** - **Image**。
  * ![image-20210708141100052](https://tuchuang-1306197151.cos.ap-shanghai.myqcloud.com/typora本地图床/image-20210708141100052.png)

## 二. pydicom的使用

[pydicom · PyPI](https://pypi.org/project/pydicom/)

<img src="https://tuchuang-1306197151.cos.ap-shanghai.myqcloud.com/typora本地图床/image-20210708171558914.png" alt="image-20210708171558914" style="zoom:80%;" />

```python
print(ds.dir("pat"))
print(ds.PatientName)
print(ds.data_element('PatientID'))
```

## 三.图像处理过程

<img src="https://tuchuang-1306197151.cos.ap-shanghai.myqcloud.com/typora本地图床/image-20210708163053763.png" alt="image-20210708163053763" style="zoom:80%;" />

#### 1. 原理

* 三维CT扫描机可以获得完整的人体虚拟模型一个人相当于面包片，而其他定向片则像是以更倾斜的角度切面包每一个CT扫描切片都是由X射线穿过身体并落在机器另一侧的X射线探测器上产生的。
* X射线通过身体的速度与途中的物质类型有关，这就是为什么在X射线图像上致密的骨骼会变成白色。低密度的器官在结果图像中看起来是灰色的，而空气是黑色的。

#### 2. 预处理

##### 1） 统一slice的间距

* ```python
  ImagePositionPatient/SliceLocation  //(问题待解决)
  ```

* CT扫描中的测量单位是Hounsfield单位（HU），它是辐射密度的量度。

* ![image-20210708165941908](https://tuchuang-1306197151.cos.ap-shanghai.myqcloud.com/typora本地图床/image-20210708165941908.png)

* ```python
  RescaleIntercept //转换为HU单位
  // 落在这些边界之外的像素获得固定值-2000。 第一步是将这些值设置为0，当前对应于air。 接下来，回到HU单位，乘以重新缩放斜率并添加截距（方便地存储在扫描的元数据中！）。
  ```

* ![image-20210708171108969](https://tuchuang-1306197151.cos.ap-shanghai.myqcloud.com/typora本地图床/image-20210708171108969.png)

* 重新采样

  * 将切片间的距离一致，可使用3D网格建模，不用担心厚度的不确定性。

##### 2）画3D图==(进一步看作用)==

  * 显示扫描3D图像，对数据有个直观的感受对处理数据是有用的。
  * 将使用立方体为我们的3D对象创建一个近似网格，并使用matplotlib绘制它。
##### 3）肺部切割==（重点保留结点）==

* 阈值图像（-320 HU是一个很好的阈值，但这种方法并不重要）
* 做连接组件，确定人周围的空气标签，在二进制图像中用1s填充
* 可选：对于扫描中的每个轴向切片，确定最大的固体连接组件（人体周围的身体+空气），并将其他组件设置为0。这样可以填充面罩中肺部的结构。
* 只保留最大的气袋（人体在这里和那里都有其他的气袋）。
* <img src="https://tuchuang-1306197151.cos.ap-shanghai.myqcloud.com/typora本地图床/image-20210708173001961.png" alt="image-20210708173001961" style="zoom:80%;" />

##### 4）数据归一化

* 目前所有的数值在-1024到2000左右。超过400的任何东西其实是不用关心的，因为只是一些具有不同辐射密度的骨骼。 常用的阈值集合在-1000到400之间。

* ```Python
  MIN_BOUND = -1000.0
  MAX_BOUND = 400.0
  
  def normalize(image):
      image = (image - MIN_BOUND) / (MAX_BOUND - MIN_BOUND)
      image[image>1] = 1.
      image[image<0] = 0.
      return image
  ```
#### 3.CNN神经网络

* 该网络是基于U-net的3D版RPN（Region Proposal Network）模型。

